# OKR ML Pipeline - Unified Dashboard

A production-ready machine learning pipeline that processes OKR (Objectives and Key Results) data through a complete ETL workflow, with real-time streaming via Kafka, workflow orchestration using Airflow, and ML experiment tracking with MLflow. Now features a modern unified dashboard for complete pipeline management.

## ğŸ¢ Project Overview

This comprehensive ML pipeline system enables organizations to:

- **Process OKR Data**: Automated ETL pipeline for CSV files containing organizational objectives and key results
- **Real-time Streaming**: Kafka-based data streaming for live data processing
- **Workflow Orchestration**: Airflow DAGs manage complex data processing workflows
- **ML Model Training**: Automated model training and evaluation with performance tracking
- **Experiment Tracking**: MLflow integration for model versioning and experiment management
- **Unified Dashboard**: Modern web interface with real-time monitoring, file management, and service control
- **File Management**: Built-in upload/download functionality for all data types
- **Production Deployment**: Docker-based deployment ready for Oracle Cloud Infrastructure

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚â”€â”€â”€â–¶â”‚  Kafka Stream   â”‚â”€â”€â”€â–¶â”‚  Airflow DAGs   â”‚
â”‚   (CSV Files)   â”‚    â”‚  (Real-time)    â”‚    â”‚ (Orchestration) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚â—€â”€â”€â”€â”‚   ETL Pipeline  â”‚â—€â”€â”€â”€â”‚  Data Processingâ”‚
â”‚  (3-tier DB)    â”‚    â”‚  (Transform)    â”‚    â”‚   (Validation)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MLflow      â”‚â—€â”€â”€â”€â”‚  Model Training â”‚â—€â”€â”€â”€â”‚   ML Pipeline   â”‚
â”‚ (Experiments)   â”‚    â”‚  (Automated)    â”‚    â”‚  (Features)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Dashboard  â”‚â—€â”€â”€â”€â”‚   Flask API     â”‚â—€â”€â”€â”€â”‚     Nginx       â”‚
â”‚   (Monitoring)  â”‚    â”‚  (REST APIs)    â”‚    â”‚ (Load Balancer) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### One-Command Setup
```bash
# Start the complete pipeline with unified dashboard
./start_unified_pipeline.sh
```

### Access Points:
- **ğŸŒŸ Unified Dashboard**: http://localhost:3000 (Main entry point)
- **ğŸ”§ OKR API**: http://localhost:5001
- **ğŸ“ˆ MLflow UI**: http://localhost:5000
- **ğŸŒŠ Airflow UI**: http://localhost:8081 (admin/admin)
- **ğŸ“ Kafka UI**: http://localhost:8085

### Dashboard Features:
- **Real-time Monitoring**: Live system metrics and service status
- **File Management**: Upload/download files with drag-and-drop interface
- **Service Control**: Start/stop/restart services directly from the UI
- **Pipeline Logs**: View real-time pipeline execution logs
- **System Analytics**: Charts and graphs for performance monitoring

For detailed setup instructions:
- See `LOCAL_SETUP.md` for local development setup
- See `ORACLE_DEPLOYMENT.md` for production deployment on Oracle Cloud

## ğŸ“ Project Structure

```
OKR/
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ dags/                   # Airflow DAGs (workflow orchestration)
â”‚   â”œâ”€â”€ models/                 # ML model training and evaluation
â”‚   â”œâ”€â”€ data/                   # Data processing and streaming
â”‚   â”œâ”€â”€ utils/                  # Utility functions and helpers
â”‚   â””â”€â”€ dashboard/              # Web dashboard application
â”œâ”€â”€ apps/                       # Application containers
â”‚   â””â”€â”€ api/                    # Flask REST API
â”œâ”€â”€ data/                       # Data storage and processing
â”‚   â”œâ”€â”€ raw/                    # Raw CSV input files
â”‚   â”œâ”€â”€ processed/              # Cleaned and transformed data
â”‚   â”œâ”€â”€ final/                  # Model-ready datasets
â”‚   â””â”€â”€ models/                 # Trained ML models and artifacts
â”œâ”€â”€ configs/                    # Configuration files
â”œâ”€â”€ deploy/                     # Production deployment configurations
â”œâ”€â”€ kafka_pipeline/             # Kafka producers and consumers
â”œâ”€â”€ scripts/                    # Utility and management scripts
â”œâ”€â”€ docker-compose.yml          # Complete service orchestration
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ *.md                        # Documentation files
```

## ğŸ”§ Core Services

- **Kafka**: Real-time data streaming and message processing
- **Airflow**: Workflow orchestration and DAG management
- **PostgreSQL**: Multi-tier data storage (raw, processed, curated)
- **MLflow**: ML experiment tracking and model versioning
- **Flask API**: REST endpoints and dashboard interface
- **Nginx**: Load balancing and reverse proxy
- **Oracle DB**: Optional enterprise database integration

## ğŸ“Š Workflow Overview

### 1. Data Ingestion
- CSV files placed in `data/raw/` are automatically discovered
- Files are processed through 3-tier database architecture:
  - **okr_raw**: Original data with metadata
  - **okr_processed**: Cleaned and validated data
  - **okr_curated**: Model-ready JSON documents

### 2. Stream Processing
- Kafka streams handle real-time data flow between components
- Topics: `okr_raw_ingest`, `okr_processed_updates`
- Reliable message delivery with configurable retention

### 3. ML Pipeline
- Automated model training triggered by data updates
- MLflow tracks experiments, parameters, and model performance
- Model evaluation and validation with automated deployment

### 4. Monitoring & Control
- Web dashboard for pipeline monitoring and control
- Airflow UI for workflow management
- Real-time metrics and alerting

## ğŸš€ Getting Started

1. **Local Development**: See `LOCAL_SETUP.md`
2. **Production Deployment**: See `ORACLE_DEPLOYMENT.md`
3. **Configuration**: See `ORACLE_CONFIG.md`

## ğŸ“ˆ Key Features

- **Production Ready**: Docker-based deployment with proper resource management
- **Scalable**: Horizontal scaling support for Kafka and database components
- **Reliable**: Health checks, restart policies, and error handling
- **Configurable**: Environment-based configuration for different deployment scenarios
- **Monitored**: Comprehensive logging and monitoring across all components

## ğŸ”— External Access

All services are accessible via the main application URL:
- **Production**: `http://YOUR_ORACLE_SERVER_IP`
- **Local**: `http://localhost`

Individual service access (development only):
- Airflow: `:8081`
- MLflow: `:5000`
- Kafka UI: `:8085`
