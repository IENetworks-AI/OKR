name: Branch Protection and Code Quality

on:
  pull_request:
    types: [opened, synchronize, reopened]
  push:
    branches: [main, develop, test]

jobs:
  # Code Quality Checks
  code-quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install flake8 black pylint pytest
      
      - name: Run code formatting check
        run: |
          echo "Checking code formatting..."
          black --check --diff .
      
      - name: Run linting
        run: |
          echo "Running linting checks..."
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      
      - name: Run unit tests
        run: |
          echo "Running unit tests..."
          python -m pytest tests/ -v --cov=. --cov-report=xml
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

  # Security Scan
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Bandit Security Scan
        run: |
          pip install bandit
          bandit -r . -f json -o bandit-report.json || true
      
      - name: Upload security scan results
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-results
          path: bandit-report.json

  # Docker Build Test
  docker-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker images
        run: |
          docker build -t okr-api:test -f api/Dockerfile .
          docker build -t okr-producer:test -f kafka_pipeline/producers/Dockerfile .
          docker build -t okr-consumer:test -f kafka_pipeline/consumers/Dockerfile .
      
      - name: Test Docker Compose
        run: |
          docker-compose -f docker-compose.yml config

  # ETL Pipeline Validation
  etl-validation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install apache-airflow kafka-python confluent-kafka
      
      - name: Validate Airflow DAGs
        run: |
          echo "Validating Airflow DAGs..."
          python -c "
          import os
          import sys
          sys.path.append('airflow_dags')
          from airflow.models import DagBag
          dagbag = DagBag('airflow_dags/dags')
          if dagbag.import_errors:
              print('DAG import errors:')
              for filename, errors in dagbag.import_errors.items():
                  print(f'{filename}: {errors}')
              sys.exit(1)
          print('All DAGs imported successfully')
          "
      
      - name: Validate Kafka Pipeline
        run: |
          echo "Validating Kafka pipeline components..."
          python -c "
          import os
          import sys
          sys.path.append('kafka_pipeline')
          
          # Check if all required files exist
          required_files = [
              'kafka_pipeline/producers/producer.py',
              'kafka_pipeline/consumers/consumer.py',
              'kafka_pipeline/schemas/okr_schema.py'
          ]
          
          for file_path in required_files:
              if not os.path.exists(file_path):
                  print(f'Missing required file: {file_path}')
                  sys.exit(1)
          
          print('All Kafka pipeline components found')
          "
      
      - name: Validate Configuration Files
        run: |
          echo "Validating configuration files..."
          python -c "
          import yaml
          import os
          
          config_files = [
              'configs/db_config.yaml',
              'configs/kafka_config.yaml',
              'configs/model_config.yaml'
          ]
          
          for config_file in config_files:
              if os.path.exists(config_file):
                  with open(config_file, 'r') as f:
                      yaml.safe_load(f)
                  print(f'✓ {config_file} is valid YAML')
              else:
                  print(f'⚠ {config_file} not found')
          "

  # Deployment Validation (Oracle Only)
  deployment-validation:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/test'
    steps:
      - uses: actions/checkout@v4
      
      - name: Validate Oracle Deployment Configuration
        run: |
          echo "Validating Oracle deployment configuration..."
          
          # Check if Oracle-specific files exist
          required_files = [
              'deploy/oracle-setup.sh',
              'deploy/mlapi.service',
              'deploy/nginx/mlapi.conf'
          ]
          
          for file_path in required_files:
              if not os.path.exists(file_path):
                  echo "Missing required deployment file: $file_path"
                  exit 1
              echo "✓ $file_path found"
          
          # Validate service configuration
          if [ -f "deploy/mlapi.service" ]; then
              echo "✓ systemd service configuration found"
          fi
          
          echo "Oracle deployment configuration validated"
      
      - name: Check Oracle Secrets
        run: |
          if [ -n "${{ secrets.ORACLE_SSH_KEY }}" ]; then
              echo "✓ Oracle SSH key configured"
          else
              echo "⚠ Oracle SSH key not configured - deployment will be skipped"
          fi
