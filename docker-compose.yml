services:
  # PostgreSQL for Airflow metadata
  airflow-db:
    image: postgres:15
    container_name: okr_airflow_db
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow_db_data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - okr_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s

  # PostgreSQL for OKR data pipeline
  postgres:
    image: postgres:15
    container_name: okr_postgres_data
    environment:
      POSTGRES_USER: okr_admin
      POSTGRES_PASSWORD: okr_password
      POSTGRES_DB: postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./deploy/postgres/init:/docker-entrypoint-initdb.d
    ports:
      - "5433:5432"
    restart: unless-stopped
    networks:
      - okr_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U okr_admin -d postgres"]
      interval: 30s
      timeout: 10s
      retries: 20
      start_period: 180s

  # Redis for Airflow
  redis:
    image: redis:7-alpine
    container_name: okr_redis
    restart: unless-stopped
    networks:
      - okr_net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 10

  # Kafka with KRaft mode
  kafka:
    image: bitnami/kafka:latest
    container_name: okr_kafka
    hostname: kafka
    environment:
      - KAFKA_KRAFT_MODE=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LOG_RETENTION_HOURS=168
      - KAFKA_CFG_LOG_SEGMENT_BYTES=1073741824
      - KAFKA_CFG_LOG_RETENTION_CHECK_INTERVAL_MS=300000
    ports:
      - "9092:9092"
    volumes:
      - kafka_data:/bitnami/kafka
    restart: unless-stopped
    depends_on:
      airflow-db:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - okr_net
    healthcheck:
      test: ["CMD-SHELL", "/opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1"]
      interval: 60s
      timeout: 20s
      retries: 15
      start_period: 120s

  # Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: okr_kafka_ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=okr
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_READONLY=false
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - okr_net

  # Airflow webserver
  airflow-webserver:
    build:
      context: .
      dockerfile: airflow.Dockerfile
    container_name: okr_airflow_webserver
    depends_on:
      airflow-db:
        condition: service_healthy
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=30e6QztCFtuew7bCiQUZiomQd0eq2eWwHf39LaQyBaU=
      - AIRFLOW__WEBSERVER__SECRET_KEY=supersecret
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=true
      - AIRFLOW__WEBSERVER__RBAC=true
      - AIRFLOW__WEBSERVER__AUTHENTICATE=true
      - AIRFLOW__WEBSERVER__AUTH_BACKEND=airflow.auth.backend.basic_auth
      - AIRFLOW__WEBSERVER__WORKERS=2
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=false
      - AIRFLOW__CORE__DEFAULT_TIMEZONE=UTC
      - AIRFLOW__WEBSERVER__HOST=0.0.0.0
      - AIRFLOW__WEBSERVER__PORT=8080
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - PYTHONPATH=/opt/airflow/src:/opt/airflow
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=okr_admin
      - POSTGRES_PASSWORD=okr_password
      - POSTGRES_PORT=5432
      - _AIRFLOW_DB_MIGRATE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin
    user: "50000:0"
    volumes:
      - ./src/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./configs:/opt/airflow/configs
      - ./logs:/opt/airflow/logs
      - ./airflow-init.sh:/airflow-init.sh
    ports:
      - "8081:8080"
    restart: unless-stopped
    networks:
      - okr_net
    command: ["airflow", "webserver"]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 120s

  # Airflow scheduler
  airflow-scheduler:
    build:
      context: .
      dockerfile: airflow.Dockerfile
    container_name: okr_airflow_scheduler
    depends_on:
      airflow-db:
        condition: service_healthy
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=30e6QztCFtuew7bCiQUZiomQd0eq2eWwHf39LaQyBaU=
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=false
      - AIRFLOW__CORE__DEFAULT_TIMEZONE=UTC
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - PYTHONPATH=/opt/airflow/src:/opt/airflow
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=okr_admin
      - POSTGRES_PASSWORD=okr_password
      - POSTGRES_PORT=5432
    user: "50000:0"
    volumes:
      - ./src/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./configs:/opt/airflow/configs
      - ./logs:/opt/airflow/logs
    restart: unless-stopped
    networks:
      - okr_net
    command: ["airflow", "scheduler"]
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --hostname $(hostname) || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 120s

  # Flask API
  api:
    build:
      context: .
      dockerfile: apps/api/Dockerfile
    container_name: okr_api
    working_dir: /app
    ports:
      - "8082:8082"
    volumes:
      - ./:/app
      - ./data:/app/data
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      airflow-db:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - okr_net
    environment:
      - PYTHONPATH=/app:/app/src
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - AIRFLOW_BASE_URL=http://airflow-webserver:8080
      - AIRFLOW_USER=admin
      - AIRFLOW_PASSWORD=admin
    command: ["gunicorn", "--bind", "0.0.0.0:8082", "--workers", "2", "--worker-class", "sync", "--timeout", "120", "--keep-alive", "5", "--max-requests", "1000", "--max-requests-jitter", "100", "apps.api.app:app"]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8082/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Nginx reverse proxy
  nginx:
    image: nginx:1.25-alpine
    container_name: okr_nginx
    ports:
      - "80:80"
    volumes:
      - ./deploy/nginx/mlapi.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      api:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - okr_net
    environment:
      - NGINX_WORKER_PROCESSES=auto
      - NGINX_WORKER_CONNECTIONS=1024
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost >/dev/null 2>&1 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # Oracle XE database
  oracle:
    image: gvenzl/oracle-xe:21-slim
    container_name: okr_oracle
    environment:
      - ORACLE_PASSWORD=oracle
      - ORACLE_DATABASE=OKR
      - APP_USER=okr_user
      - APP_USER_PASSWORD=okr_password
    ports:
      - "1521:1521"
      - "5500:5500"
    volumes:
      - oracle_data:/opt/oracle/oradata
    restart: unless-stopped
    networks:
      - okr_net
    healthcheck:
      test: ["CMD-SHELL", "echo 'SELECT 1 FROM DUAL;' | sqlplus -s okr_user/okr_password@//localhost:1521/OKR"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 120s

  # MLflow tracking server
  mlflow:
    image: python:3.11-slim
    container_name: okr_mlflow
    ports:
      - "5001:5001"  # Changed port to avoid conflicts with dashboard
    volumes:
      - ./:/app
      - mlflow_data:/mlflow
      - ./requirements.txt:/requirements.txt
    working_dir: /app
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - MLFLOW_TRACKING_URI=http://0.0.0.0:5001
      - MLFLOW_BACKEND_STORE_URI=postgresql://okr_admin:okr_password@postgres:5432/postgres
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlflow/artifacts
      - MLFLOW_SERVE_ARTIFACTS=true
      - PYTHONPATH=/app:/app/src
    command: >
      bash -c "apt-get update && apt-get install -y gcc g++ curl && 
               pip install --no-cache-dir mlflow==2.8.1 psycopg2-binary==2.9.9 pandas scikit-learn boto3 &&
               mlflow server --host 0.0.0.0 --port 5001 
               --backend-store-uri postgresql://okr_admin:okr_password@postgres:5432/postgres 
               --default-artifact-root /mlflow/artifacts 
               --serve-artifacts"
    restart: unless-stopped
    networks:
      - okr_net
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5001/api/2.0/mlflow/experiments/list || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 15
      start_period: 180s

  # Unified Dashboard - Main Entry Point
  dashboard:
    image: python:3.11-slim
    container_name: okr_unified_dashboard
    ports:
      - "5000:5000"  # Main dashboard port (moved from MLflow)
    volumes:
      - ./:/app
      - ./data:/app/data
      - /var/run/docker.sock:/var/run/docker.sock
    working_dir: /app
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      mlflow:
        condition: service_healthy
    environment:
      - PYTHONPATH=/app:/app/src:/app/apps
      - FLASK_ENV=production
      - FLASK_DEBUG=0
      - MLFLOW_TRACKING_URI=http://mlflow:5001
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - DATABASE_URL=postgresql://okr_admin:okr_password@postgres:5432/postgres
    command: >
      bash -c "apt-get update && apt-get install -y gcc g++ curl docker.io && 
               pip install --no-cache-dir -r dashboard_requirements.txt &&
               python dashboard_main.py"
    restart: unless-stopped
    networks:
      - okr_net
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s

  # OKR API Service
  okr-api:
    image: python:3.11-slim
    container_name: okr_api_service
    ports:
      - "8083:8083"
    volumes:
      - ./:/app
      - ./data:/app/data
    working_dir: /app
    depends_on:
      postgres:
        condition: service_healthy
      mlflow:
        condition: service_healthy
    environment:
      - PYTHONPATH=/app:/app/src:/app/apps
      - FLASK_ENV=production
      - AIRFLOW_BASE_URL=http://airflow-webserver:8080
      - AIRFLOW_USER=admin
      - AIRFLOW_PASSWORD=admin
    command: >
      bash -c "apt-get update && apt-get install -y gcc g++ curl && 
               pip install --no-cache-dir flask requests joblib scikit-learn pandas numpy psycopg2-binary &&
               python apps/api/app.py --host 0.0.0.0 --port 8083"
    restart: unless-stopped
    networks:
      - okr_net
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5001/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s

volumes:
  airflow_db_data:
  postgres_data:
  kafka_data:
  oracle_data:
  mlflow_data:

networks:
  okr_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
